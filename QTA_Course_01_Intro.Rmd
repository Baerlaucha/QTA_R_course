---
title: 'QTA with R: Intro'
author: "Julian Bernauer"
date: "11 February 2019"
output:
  ioslides_presentation:
    incremental: no
    smaller: no
    widescreen: no
  beamer_presentation:
    incremental: no
---

```{r "knitr config", cache = FALSE, include=FALSE}
require("knitr")
opts_knit$set(root.dir = "C:/DRJB/QTA Kurs CDSS/")
```

## agenda

- What's in a word 
- Who are you 
- Course outline 
- Warm-up exercise  


## motivation: qta 

- (Political) text is everywhere 
- Digitalization, the internet and social media 
- Advances in machine learning and natural language processing 
- R and Python help social scientists find well-paid jobs outside academia \$_\$


## motivation: this course 

- Kind of a funny story: EPSA 2015 Vienna leading to a contract for a SAGE textbook "Quantitative Text Analysis with R: Scraping, Preparing, Visualising and Modelling Data"
- "Building on a longstanding tradition of quantitative text and content analysis in political science and other disciplines, the book shows how to tame the vast amounts of text available in the digital age. The methods demonstrated allow for instance teasing measures of populism out of Tweets. The book enables researchers at all levels of experience to navigate from initial texts to substantial analysis."
- Testing the material for SAGE: feedback more than welcome! 


## quick round of introduction 

- who are you 
- background 
- experience/interest in qta 


## running examples 

- European election manifestos (cross-lingual texts from European countries, using existing online resources/polidoc.net)
- Selected books by Mark Twain (English texts from the United States, using R's gutenberger package)
- Larger amounts of Tweets (representing webscraping and "bigger" data)
- Further sources: selected Wikipedia entries, speeches or other 


## literature: books on qta in R and R 

- Silge and Robinson (2017): Text Mining with R. O'Reilly. 
- Ignatow and Mihalcea (2017): Text Mining. SAGE. 
- Wickham and Grolemund (2017): R for Data Science. O'Reilly. 
- Forthcoming: Bernauer (2020): Quantitative Text Analysis with R. SAGE. 
- Forthcoming: Benoit and Nulty (XXXX): Quantitative Text Analysis Using R.  


## course outline 

- The working environment: R, quanteda, tidyverse, Python called from R  
- Turning text into data: read, scrape, transform...  
- Playing around with text as data: information retrieval and visualization
- Analyzing text as data: classification and scaling 


## part I: the working environment 

- R: free and open source 
- quanteda: taking QTA in R by storm 
- tidyverse: "better" R 
- Python: maybe more programming power/currently more tools for NLP (natural language processing) -> we'll call it from R 

![RStudio's reticulate()](C:/DRJB/QTA Kurs CDSS/pics/reticulated_python.png)


## part II: turning text into data 

- Obtaining text from various file formats and online sources (including webscraping)
- Creating a text corpus using quanteda
- (dis-)aggregating at different levels 
- Counting word frequencies 
- Text filtering using dictionaries 


## part III: playing around with text  

- Descriptive analysis of text as data
- Sentiment analysis 
- A critique of the word cloud 
- Better visualizations using R 


## part IV: analyzing text as data  

- The really interesting stuff ;) 
- Reducing textual data to answer substantial (research) questions 
- Classification: e.g. spam or not? -> plethora of algorithms such as Latent Dirichlet Allocation (LDA)
- Scaling: e.g. political left-right dimension -> Wordscores, Wordfish and beyond (word embeddings)


## warm-up example and exercise 

1. European party manifestos: [polidoc.net](http://polidoc.net/) (quick registration needed)
2. R and quanteda: starting a session
3. Creating a text corpus 
4. Counting word frequencies 
5. Wordfish scaling "left-right"
6. Creating a word cloud 

Example using 2017 Bundestag election, then repeat with earlier election 


## polidoc.net 

- [polidoc.net](http://polidoc.net/) (political documents archive) houses several thousand party manifestos and other political documents from Europe 
- Maintained at the University of Mannheim/MZES 
- Texts are preprocessed to facilitate QTA (raw text, encoded in UTF-8 -> can still cause problems) 
- German manifestos from 2017 election as example 
- See also [CMP project](https://manifesto-project.wzb.eu/) for data coding text units 


## R and quanteda 
To start up R and quanteda
- Use R with R Studio
- Install Rtools for Windows 
- Within R, install quanteda 
- See [quanteda](https://quanteda.io/) for documentation 

```{r quanteda, eval=TRUE, echo=TRUE, comment=FALSE}
library(quanteda)
```


## reading texts in using readtext()

- Readtext package 
- Works at the level of whole directories 
- Need to specify encoding -> Windows messes around 
- Creates data frame (df)


## reading texts in using readtext()

```{r readtext, eval=TRUE, echo=TRUE}
library(readtext)
df_btw17 <- readtext("C:/DRJB/QTA Kurs CDSS/data/btw2017", 
                     encoding="UTF-8-BOM")
head(df_btw17)
```


## creating a text corpus 

- Using quanteda's corpus() command  
- Finds text identifier doc_id
- Provides metainformation, counts of types, tokens and sentences 
- Starting point for adding metainformation, subsetting, word frequency matrix generation... 

For help
```{r corpus_help, eval=FALSE, echo=FALSE}
?corpus()
```


## creating a text corpus 

```{r corpus, eval=TRUE, echo=TRUE}
corpus_btw17 <- corpus(df_btw17)
summary(corpus_btw17)
```


## adding document variables  

```{r docvars, eval=TRUE, echo=TRUE}
docvars(corpus_btw17, "party") <- 
  c("Grüne","Linke","SPD","FDP","CDU","CSU","AfD")
summary(corpus_btw17)
```


## creating a document-feature matrix (dfm)
- not to be confused with a data frame (df)
- distribution of words (more generally: features, could be emoticons) across texts 
- starting point for bag-of-words approaches (omits position of words in texts)


## creating a document-feature matrix (dfm)

```{r dfm, eval=TRUE, echo=TRUE}
dfm_btw17 <- dfm(corpus_btw17)
head(dfm_btw17, 7, nf = 5)
```


## removing stopwords and punctuation 

```{r dfm2, eval=TRUE, echo=TRUE}
dfm_btw17 <- dfm(corpus_btw17, 
                 remove = stopwords(language = "de"), 
                 remove_punct = TRUE)
head(dfm_btw17, 7, nf = 5)
```


## wordfish for left-right scaling 
- Wordfish (Slapin and Proksch 2008) is a bag-of-word approach scaling from the relative distribution of words
- Requires fixing the relative positions of two texts, here Linke (2) < CSU (6), aiming at a left-right dimension  
- theta = document position (that's what we want)
- alpha = document fixed effect (accounts for text length)
- beta = feature marginal effect (the "word weights" shaping the text positions)
- psi = word fixed effect (accounts for absolut frequency) 

For help 
```{r wordfish_help, eval=FALSE, echo=FALSE}
?textmodel_wordfish()
```


## wordfish estimation

```{r wordfish, eval=FALSE, echo=TRUE}
fish_btw17 <- textmodel_wordfish(dfm_btw17, 
                                 dir = c(2,6)) 
summary(fish_btw17, n = 5)
```


## wordfish results

```{r wordfish_out, eval=TRUE, echo=FALSE}
fish_btw17 <- textmodel_wordfish(dfm_btw17, 
                                 dir = c(2,6)) 
summary(fish_btw17, n = 5)
```


## wordfish visualization of text positions 

```{r positions, eval=TRUE, echo=TRUE}
textplot_scale1d(fish_btw17, doclabels=docvars(corpus_btw17, "party"))
```


## wordfish visualization words

```{r features, eval=TRUE, echo=TRUE}
textplot_scale1d(fish_btw17, margin = "features", 
                 highlighted = c("eliten","volk","souverän","deutschland"))
```



## creating a quick word cloud for the AfD 

```{r wordcloud, eval=TRUE, echo=TRUE}
dfm_afd <- dfm(corpus_subset(corpus_btw17, party=="AfD"), 
               remove = c(stopwords(language = "de"),"afd","dass"), 
               remove_punct = TRUE)
textplot_wordcloud(dfm_afd, max_words = 100, min_count = 3, 
                   color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
```


## warm-up exercise using earlier election 

1. Register on [polidoc.net](http://polidoc.net/) if not done yet, download manifestos of an earlier Bundestag election, put them in a folder 
2. Create a text corpus  
3. Create a document variable "party"
4. Create a dfm
5. Wordfish scaling "left-right"
6. Create a word cloud for the Green party


## that's all folks 

THANK YOU!

*Contact Julian Bernauer*

- Postdoctoral Fellow, MZES, Data and Methods Unit
- julian.bernauer@mzes.uni-mannheim.de
- [julianbernauer.github.io](https:/julianbernauer.github.io)
- +49 621 181 2853

